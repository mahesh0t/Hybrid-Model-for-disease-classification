{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "48c3c7d3-15d4-46ee-9b15-511a8560ffaa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Manual: (8400, 14)\n",
      "MobileNet: (8400, 1280)\n",
      "DenseNet: (8400, 1024)\n",
      "Labels: (8400,)\n",
      "Combined train shape: (8400, 2318)\n",
      "Combined test shape: (1400, 2318)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "# Load features\n",
    "train_manual = np.load(\"featuresets/train_manual_features.npy\")\n",
    "test_manual = np.load(\"featuresets/test_manual_features.npy\")\n",
    "\n",
    "train_mobilenet = np.load(\"featuresets/train_mobilenet_features.npy\")\n",
    "test_mobilenet = np.load(\"featuresets/test_mobilenet_features.npy\")\n",
    "\n",
    "train_densenet = np.load(\"featuresets/train_densenet_features.npy\")\n",
    "test_densenet = np.load(\"featuresets/test_densenet_features.npy\")\n",
    "\n",
    "train_labels = np.load(\"featuresets/train_manual_labels.npy\")  # All labels are aligned\n",
    "test_labels = np.load(\"featuresets/test_manual_labels.npy\")\n",
    "\n",
    "# Check dimensions\n",
    "print(\"Manual:\", train_manual.shape)\n",
    "print(\"MobileNet:\", train_mobilenet.shape)\n",
    "print(\"DenseNet:\", train_densenet.shape)\n",
    "print(\"Labels:\", train_labels.shape)\n",
    "\n",
    "# Combine features\n",
    "X_train = np.hstack((train_manual, train_mobilenet, train_densenet))\n",
    "X_test = np.hstack((test_manual, test_mobilenet, test_densenet))\n",
    "\n",
    "print(\"Combined train shape:\", X_train.shape)\n",
    "print(\"Combined test shape:\", X_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "16958b92-7041-40e3-b811-a1c277dbbe71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üîπ SVM Classifier\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.72      0.72       200\n",
      "           1       0.90      0.92      0.91       200\n",
      "           2       0.70      0.68      0.69       200\n",
      "           3       0.84      0.81      0.83       200\n",
      "           4       0.89      0.90      0.90       200\n",
      "           5       0.79      0.75      0.77       200\n",
      "           6       0.65      0.70      0.67       200\n",
      "\n",
      "    accuracy                           0.78      1400\n",
      "   macro avg       0.78      0.78      0.78      1400\n",
      "weighted avg       0.78      0.78      0.78      1400\n",
      "\n",
      "SVM Accuracy: 0.7821428571428571\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nüîπ SVM Classifier\")\n",
    "svm = SVC(kernel='rbf', probability=True, random_state=42)\n",
    "svm.fit(X_train, train_labels)\n",
    "y_pred = svm.predict(X_test)\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(test_labels, y_pred))\n",
    "print(\"SVM Accuracy:\", accuracy_score(test_labels, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8aee945e-b242-4dc7-8f1a-b1eee2772ecb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üßº Removed Class 6\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.75      0.75       200\n",
      "           1       0.89      0.92      0.90       200\n",
      "           2       0.77      0.78      0.78       200\n",
      "           3       0.82      0.82      0.82       200\n",
      "           4       0.90      0.88      0.89       200\n",
      "           5       0.80      0.79      0.80       200\n",
      "\n",
      "    accuracy                           0.82      1200\n",
      "   macro avg       0.82      0.82      0.82      1200\n",
      "weighted avg       0.82      0.82      0.82      1200\n",
      "\n",
      "Filtered SVM Accuracy: 0.8225\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "# üîÅ Load combined feature arrays and labels (already loaded if you're in Colab)\n",
    "# X_train, X_test, train_labels, test_labels already defined\n",
    "# If not, reload them before this block.\n",
    "\n",
    "# üéØ Remove class 6 from training and testing sets\n",
    "class_to_remove = 6\n",
    "\n",
    "train_mask = train_labels != class_to_remove\n",
    "test_mask = test_labels != class_to_remove\n",
    "\n",
    "X_train_filtered = X_train[train_mask]\n",
    "X_test_filtered = X_test[test_mask]\n",
    "y_train_filtered = train_labels[train_mask]\n",
    "y_test_filtered = test_labels[test_mask]\n",
    "\n",
    "# üîÑ Train SVM\n",
    "svm = SVC(probability=True, kernel='rbf', C=10, gamma='scale', random_state=42)\n",
    "svm.fit(X_train_filtered, y_train_filtered)\n",
    "y_pred = svm.predict(X_test_filtered)\n",
    "\n",
    "# üìä Evaluate\n",
    "print(\"\\nüßº Removed Class 6\")\n",
    "print(classification_report(y_test_filtered, y_pred))\n",
    "print(\"Filtered SVM Accuracy:\", accuracy_score(y_test_filtered, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bc548bf2-567b-43d9-9d4e-aa201f62fb12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üîπ XGBoost Classifier\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [02:09:51] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.67      0.70       200\n",
      "           1       0.85      0.92      0.88       200\n",
      "           2       0.66      0.65      0.66       200\n",
      "           3       0.83      0.76      0.79       200\n",
      "           4       0.88      0.88      0.88       200\n",
      "           5       0.70      0.76      0.73       200\n",
      "           6       0.64      0.68      0.66       200\n",
      "\n",
      "    accuracy                           0.76      1400\n",
      "   macro avg       0.76      0.76      0.76      1400\n",
      "weighted avg       0.76      0.76      0.76      1400\n",
      "\n",
      "XGBoost Accuracy: 0.7564285714285715\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nüîπ XGBoost Classifier\")\n",
    "xgb = XGBClassifier(use_label_encoder=False, eval_metric='mlogloss', random_state=42)\n",
    "xgb.fit(X_train, train_labels)\n",
    "y_pred = xgb.predict(X_test)\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(test_labels, y_pred))\n",
    "print(\"XGBoost Accuracy:\", accuracy_score(test_labels, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fcb89849-19a8-4d77-b4c6-3fc80517e997",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üîπ Logistic Regression\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.58      0.62       200\n",
      "           1       0.85      0.90      0.87       200\n",
      "           2       0.57      0.56      0.57       200\n",
      "           3       0.80      0.76      0.78       200\n",
      "           4       0.87      0.87      0.87       200\n",
      "           5       0.66      0.66      0.66       200\n",
      "           6       0.61      0.70      0.65       200\n",
      "\n",
      "    accuracy                           0.72      1400\n",
      "   macro avg       0.72      0.72      0.72      1400\n",
      "weighted avg       0.72      0.72      0.72      1400\n",
      "\n",
      "Logistic Regression Accuracy: 0.7178571428571429\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nüîπ Logistic Regression\")\n",
    "lr = LogisticRegression(max_iter=1000, random_state=42)\n",
    "lr.fit(X_train, train_labels)\n",
    "y_pred = lr.predict(X_test)\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(test_labels, y_pred))\n",
    "print(\"Logistic Regression Accuracy:\", accuracy_score(test_labels, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "66859d34-0546-4d0b-ad7a-539b4c993713",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üîπ Random Forest\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.66      0.69       200\n",
      "           1       0.84      0.90      0.87       200\n",
      "           2       0.65      0.67      0.66       200\n",
      "           3       0.80      0.73      0.76       200\n",
      "           4       0.87      0.89      0.88       200\n",
      "           5       0.73      0.71      0.72       200\n",
      "           6       0.60      0.66      0.63       200\n",
      "\n",
      "    accuracy                           0.74      1400\n",
      "   macro avg       0.75      0.74      0.74      1400\n",
      "weighted avg       0.75      0.74      0.74      1400\n",
      "\n",
      "Random Forest Accuracy: 0.7442857142857143\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nüîπ Random Forest\")\n",
    "rf = RandomForestClassifier(n_estimators=150, random_state=42)\n",
    "rf.fit(X_train, train_labels)\n",
    "y_pred = rf.predict(X_test)\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(test_labels, y_pred))\n",
    "print(\"Random Forest Accuracy:\", accuracy_score(test_labels, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "38f9375c-1943-4da3-874c-031bd122dcf3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [03:52:28] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "D:\\Anaconda\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [04:11:18] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "D:\\Anaconda\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [04:13:17] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "D:\\Anaconda\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [04:15:20] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "D:\\Anaconda\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [04:17:24] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "D:\\Anaconda\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [04:19:28] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üîó [Stacked Model Results]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.66      0.69       200\n",
      "           1       0.88      0.90      0.89       200\n",
      "           2       0.67      0.67      0.67       200\n",
      "           3       0.81      0.81      0.81       200\n",
      "           4       0.92      0.89      0.90       200\n",
      "           5       0.72      0.75      0.73       200\n",
      "           6       0.66      0.69      0.67       200\n",
      "\n",
      "    accuracy                           0.77      1400\n",
      "   macro avg       0.77      0.77      0.77      1400\n",
      "weighted avg       0.77      0.77      0.77      1400\n",
      "\n",
      "Stacked Accuracy: 0.7664285714285715\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import StackingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "# Define base classifiers\n",
    "base_learners = [\n",
    "    ('svm', SVC(probability=True, random_state=42)),\n",
    "    ('xgb', XGBClassifier(use_label_encoder=False, eval_metric='mlogloss', random_state=42)),\n",
    "    ('lr', LogisticRegression(max_iter=1000, random_state=42))\n",
    "]\n",
    "\n",
    "# Meta-learner\n",
    "meta_model = LogisticRegression(max_iter=1000, random_state=42)\n",
    "\n",
    "# Build stacking classifier\n",
    "stacked_clf = StackingClassifier(estimators=base_learners, final_estimator=meta_model, cv=5)\n",
    "\n",
    "# Train\n",
    "stacked_clf.fit(X_train, train_labels)\n",
    "\n",
    "# Predict\n",
    "y_pred = stacked_clf.predict(X_test)\n",
    "\n",
    "# Evaluate\n",
    "print(\"\\nüîó [Stacked Model Results]\")\n",
    "print(classification_report(test_labels, y_pred))\n",
    "print(\"Stacked Accuracy:\", accuracy_score(test_labels, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2ec85963-50eb-4764-8d8b-2e9a68092998",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Manual: (8400, 14)\n",
      "MobileNet: (8400, 1280)\n",
      "DenseNet: (8400, 1024)\n",
      "Labels: (8400,)\n",
      "Combined train shape: (8400, 2318)\n",
      "Combined test shape: (1400, 2318)\n",
      "Reduced train shape: (8400, 1500)\n",
      "Reduced test shape: (1400, 1500)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "# Load features\n",
    "train_manual = np.load(\"featuresets/train_manual_features.npy\")\n",
    "test_manual = np.load(\"featuresets/test_manual_features.npy\")\n",
    "\n",
    "train_mobilenet = np.load(\"featuresets/train_mobilenet_features.npy\")\n",
    "test_mobilenet = np.load(\"featuresets/test_mobilenet_features.npy\")\n",
    "\n",
    "train_densenet = np.load(\"featuresets/train_densenet_features.npy\")\n",
    "test_densenet = np.load(\"featuresets/test_densenet_features.npy\")\n",
    "\n",
    "train_labels = np.load(\"featuresets/train_manual_labels.npy\")  # All labels are aligned\n",
    "test_labels = np.load(\"featuresets/test_manual_labels.npy\")\n",
    "\n",
    "# Check dimensions\n",
    "print(\"Manual:\", train_manual.shape)\n",
    "print(\"MobileNet:\", train_mobilenet.shape)\n",
    "print(\"DenseNet:\", train_densenet.shape)\n",
    "print(\"Labels:\", train_labels.shape)\n",
    "\n",
    "# Combine features\n",
    "X_train = np.hstack((train_manual, train_mobilenet, train_densenet))\n",
    "X_test = np.hstack((test_manual, test_mobilenet, test_densenet))\n",
    "\n",
    "print(\"Combined train shape:\", X_train.shape)\n",
    "print(\"Combined test shape:\", X_test.shape)\n",
    "\n",
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "\n",
    "#  Apply SelectKBest\n",
    "k = 1500  # You can change this to test different numbers\n",
    "selector = SelectKBest(score_func=f_classif, k=k)\n",
    "\n",
    "X_train_reduced = selector.fit_transform(X_train, train_labels)\n",
    "X_test_reduced = selector.transform(X_test)\n",
    "\n",
    "print(\"Reduced train shape:\", X_train_reduced.shape)\n",
    "print(\"Reduced test shape:\", X_test_reduced.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "758cf290-6f49-477b-8f4b-e41746fdab27",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [07:38:52] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "D:\\Anaconda\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "D:\\Anaconda\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [07:51:54] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "D:\\Anaconda\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [07:53:20] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "D:\\Anaconda\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [07:54:48] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "D:\\Anaconda\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [07:56:17] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "D:\\Anaconda\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [07:57:46] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üîó [Stacked Model Results]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.67      0.69       200\n",
      "           1       0.91      0.91      0.91       200\n",
      "           2       0.69      0.63      0.66       200\n",
      "           3       0.83      0.85      0.84       200\n",
      "           4       0.93      0.89      0.91       200\n",
      "           5       0.72      0.74      0.73       200\n",
      "           6       0.61      0.70      0.65       200\n",
      "\n",
      "    accuracy                           0.77      1400\n",
      "   macro avg       0.77      0.77      0.77      1400\n",
      "weighted avg       0.77      0.77      0.77      1400\n",
      "\n",
      "Stacked Accuracy: 0.77\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import StackingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "# Define base classifiers\n",
    "base_learners = [\n",
    "    ('svm', SVC(probability=True, random_state=42)),\n",
    "    ('xgb', XGBClassifier(use_label_encoder=False, eval_metric='mlogloss', random_state=42)),\n",
    "    ('lr', LogisticRegression(max_iter=1000, random_state=42))\n",
    "]\n",
    "\n",
    "# Meta-learner\n",
    "meta_model = LogisticRegression(max_iter=1000, random_state=42)\n",
    "\n",
    "# Build stacking classifier\n",
    "stacked_clf = StackingClassifier(estimators=base_learners, final_estimator=meta_model, cv=5)\n",
    "\n",
    "# Train\n",
    "# Train on reduced features\n",
    "stacked_clf.fit(X_train_reduced, train_labels)\n",
    "y_pred = stacked_clf.predict(X_test_reduced)\n",
    "\n",
    "\n",
    "# Evaluate\n",
    "print(\"\\nüîó [Stacked Model Results]\")\n",
    "print(classification_report(test_labels, y_pred))\n",
    "print(\"Stacked Accuracy:\", accuracy_score(test_labels, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1e37fd35-ecf3-4382-b0c8-79456b83ff70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Manual: (8400, 14)\n",
      "MobileNet: (8400, 1280)\n",
      "DenseNet: (8400, 1024)\n",
      "Labels: (8400,)\n",
      "Combined train shape: (8400, 2318)\n",
      "Combined test shape: (1400, 2318)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "# Load features\n",
    "train_manual = np.load(\"featuresets/train_manual_features.npy\")\n",
    "test_manual = np.load(\"featuresets/test_manual_features.npy\")\n",
    "\n",
    "train_mobilenet = np.load(\"featuresets/train_mobilenet_features.npy\")\n",
    "test_mobilenet = np.load(\"featuresets/test_mobilenet_features.npy\")\n",
    "\n",
    "train_densenet = np.load(\"featuresets/train_densenet_features.npy\")\n",
    "test_densenet = np.load(\"featuresets/test_densenet_features.npy\")\n",
    "\n",
    "train_labels = np.load(\"featuresets/train_manual_labels.npy\")  # All labels are aligned\n",
    "test_labels = np.load(\"featuresets/test_manual_labels.npy\")\n",
    "\n",
    "# Check dimensions\n",
    "print(\"Manual:\", train_manual.shape)\n",
    "print(\"MobileNet:\", train_mobilenet.shape)\n",
    "print(\"DenseNet:\", train_densenet.shape)\n",
    "print(\"Labels:\", train_labels.shape)\n",
    "\n",
    "# Combine features\n",
    "X_train = np.hstack((train_manual, train_mobilenet, train_densenet))\n",
    "X_test = np.hstack((test_manual, test_mobilenet, test_densenet))\n",
    "\n",
    "print(\"Combined train shape:\", X_train.shape)\n",
    "print(\"Combined test shape:\", X_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cccb1ce7-58a5-4fc9-b212-2f993c26b764",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [08:13:04] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "D:\\Anaconda\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [08:33:48] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "D:\\Anaconda\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [08:36:04] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "D:\\Anaconda\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [08:38:19] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "D:\\Anaconda\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [08:40:38] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "D:\\Anaconda\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [08:43:03] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üîó [Stacked Model Results]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.67      0.71       200\n",
      "           1       0.89      0.92      0.90       200\n",
      "           2       0.67      0.65      0.66       200\n",
      "           3       0.84      0.81      0.82       200\n",
      "           4       0.90      0.91      0.90       200\n",
      "           5       0.70      0.76      0.73       200\n",
      "           6       0.65      0.69      0.67       200\n",
      "\n",
      "    accuracy                           0.77      1400\n",
      "   macro avg       0.77      0.77      0.77      1400\n",
      "weighted avg       0.77      0.77      0.77      1400\n",
      "\n",
      "Stacked Accuracy: 0.7714285714285715\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import StackingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "# Define base classifiers\n",
    "base_learners = [\n",
    "    ('svm', SVC(probability=True, C=1.0, gamma='scale', random_state=42)),\n",
    "    ('xgb', XGBClassifier(use_label_encoder=False, eval_metric='mlogloss', random_state=42)),\n",
    "    ('rf', RandomForestClassifier(n_estimators=150, random_state=42))  # optional\n",
    "]\n",
    "\n",
    "meta_model = LogisticRegression(max_iter=1000, random_state=42)\n",
    "\n",
    "# Build stacking classifier\n",
    "stacked_clf = StackingClassifier(estimators=base_learners, final_estimator=meta_model, cv=5)\n",
    "\n",
    "# Train\n",
    "stacked_clf.fit(X_train, train_labels)\n",
    "\n",
    "# Predict\n",
    "y_pred = stacked_clf.predict(X_test)\n",
    "\n",
    "# Evaluate\n",
    "print(\"\\nüîó [Stacked Model Results]\")\n",
    "print(classification_report(test_labels, y_pred))\n",
    "print(\"Stacked Accuracy:\", accuracy_score(test_labels, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2afb7623-eed2-42cb-9692-7f92a492992e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
