{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ca15f068-35d4-48e5-a481-9f3869533783",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MobileNet features: (8757, 1280)\n",
      "DenseNet features: (8757, 1024)\n",
      "Manual features: (8757, 18)\n",
      "Labels: (8757,)\n",
      "Combined feature shape: (8757, 2322)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [23:53:54] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.71      0.67       300\n",
      "           1       0.87      0.94      0.90       200\n",
      "           2       0.59      0.49      0.53       252\n",
      "           3       0.86      0.82      0.84       200\n",
      "           4       0.91      0.88      0.89       200\n",
      "           5       0.67      0.68      0.68       300\n",
      "           6       0.60      0.62      0.61       300\n",
      "\n",
      "    accuracy                           0.71      1752\n",
      "   macro avg       0.73      0.73      0.73      1752\n",
      "weighted avg       0.71      0.71      0.71      1752\n",
      "\n",
      "XGBoost Accuracy: 0.714041095890411\n"
     ]
    }
   ],
   "source": [
    "#Mobilenet + Densenet + Manual\n",
    "#XGBoost\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "# Load features and labels\n",
    "mobilenet_features = np.load(\"oversampled_featuresets/ovs_mobilenet_features.npy\")\n",
    "densenet_features = np.load(\"oversampled_featuresets/ovs_densenet_features.npy\")\n",
    "manual_features = np.load(\"oversampled_featuresets/ovs_manual_features.npy\")\n",
    "labels = np.load(\"oversampled_featuresets/ovs_resnet_labels.npy\")  # assuming consistent labels\n",
    "\n",
    "# Check dimensions\n",
    "print(\"MobileNet features:\", mobilenet_features.shape)\n",
    "print(\"DenseNet features:\", densenet_features.shape)\n",
    "print(\"Manual features:\", manual_features.shape)\n",
    "print(\"Labels:\", labels.shape)\n",
    "\n",
    "# Concatenate all features\n",
    "combined_features = np.hstack((mobilenet_features, densenet_features, manual_features))\n",
    "print(\"Combined feature shape:\", combined_features.shape)\n",
    "\n",
    "# Handle missing values\n",
    "imputer = SimpleImputer(strategy='mean')\n",
    "combined_features = imputer.fit_transform(combined_features)\n",
    "\n",
    "# Normalize\n",
    "scaler = StandardScaler()\n",
    "combined_features = scaler.fit_transform(combined_features)\n",
    "\n",
    "# Split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    combined_features, labels, test_size=0.2, random_state=42, stratify=labels\n",
    ")\n",
    "\n",
    "# Train XGBoost\n",
    "model = XGBClassifier(use_label_encoder=False, eval_metric='mlogloss', random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Predict and evaluate\n",
    "y_pred = model.predict(X_test)\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(\"XGBoost Accuracy:\", accuracy_score(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d30b3f17-c126-416e-b9d2-6177bd3dc968",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MobileNet features: (8757, 1280)\n",
      "DenseNet features: (8757, 1024)\n",
      "Manual features: (8757, 18)\n",
      "Labels: (8757,)\n",
      "Combined feature shape: (8757, 2322)\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.70      0.70       300\n",
      "           1       0.91      0.92      0.92       200\n",
      "           2       0.67      0.56      0.61       252\n",
      "           3       0.86      0.84      0.85       200\n",
      "           4       0.88      0.89      0.88       200\n",
      "           5       0.67      0.68      0.67       300\n",
      "           6       0.60      0.67      0.63       300\n",
      "\n",
      "    accuracy                           0.73      1752\n",
      "   macro avg       0.75      0.75      0.75      1752\n",
      "weighted avg       0.73      0.73      0.73      1752\n",
      "\n",
      "SVM Accuracy: 0.7323059360730594\n"
     ]
    }
   ],
   "source": [
    "#SVM\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "# Load features and labels\n",
    "mobilenet_features = np.load(\"oversampled_featuresets/ovs_mobilenet_features.npy\")\n",
    "densenet_features = np.load(\"oversampled_featuresets/ovs_densenet_features.npy\")\n",
    "manual_features = np.load(\"oversampled_featuresets/ovs_manual_features.npy\")\n",
    "labels = np.load(\"oversampled_featuresets/ovs_resnet_labels.npy\")  # assuming consistent labels\n",
    "\n",
    "# Check dimensions\n",
    "print(\"MobileNet features:\", mobilenet_features.shape)\n",
    "print(\"DenseNet features:\", densenet_features.shape)\n",
    "print(\"Manual features:\", manual_features.shape)\n",
    "print(\"Labels:\", labels.shape)\n",
    "\n",
    "# Concatenate features\n",
    "combined_features = np.hstack((mobilenet_features, densenet_features, manual_features))\n",
    "print(\"Combined feature shape:\", combined_features.shape)\n",
    "\n",
    "# Handle missing values\n",
    "imputer = SimpleImputer(strategy='mean')\n",
    "combined_features = imputer.fit_transform(combined_features)\n",
    "\n",
    "# Normalize features\n",
    "scaler = StandardScaler()\n",
    "combined_features = scaler.fit_transform(combined_features)\n",
    "\n",
    "# Split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    combined_features, labels, test_size=0.2, random_state=42, stratify=labels\n",
    ")\n",
    "\n",
    "# Train SVM\n",
    "model = SVC(kernel='rbf', random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Predict and evaluate\n",
    "y_pred = model.predict(X_test)\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(\"SVM Accuracy:\", accuracy_score(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bb587f92-cdc0-4665-b9a5-b814cdf3e8a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MobileNet features: (8757, 1280)\n",
      "DenseNet features: (8757, 1024)\n",
      "Manual features: (8757, 18)\n",
      "Labels: (8757,)\n",
      "Combined feature shape: (8757, 2322)\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.55      0.65      0.60       300\n",
      "           1       0.89      0.90      0.89       200\n",
      "           2       0.60      0.44      0.51       252\n",
      "           3       0.85      0.83      0.84       200\n",
      "           4       0.88      0.88      0.88       200\n",
      "           5       0.57      0.54      0.56       300\n",
      "           6       0.57      0.62      0.59       300\n",
      "\n",
      "    accuracy                           0.67      1752\n",
      "   macro avg       0.70      0.69      0.69      1752\n",
      "weighted avg       0.67      0.67      0.67      1752\n",
      "\n",
      "Logistic Regression Accuracy: 0.6712328767123288\n"
     ]
    }
   ],
   "source": [
    "#Logistic Regression\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "# Load features and labels\n",
    "mobilenet_features = np.load(\"oversampled_featuresets/ovs_mobilenet_features.npy\")\n",
    "densenet_features = np.load(\"oversampled_featuresets/ovs_densenet_features.npy\")\n",
    "manual_features = np.load(\"oversampled_featuresets/ovs_manual_features.npy\")\n",
    "labels = np.load(\"oversampled_featuresets/ovs_resnet_labels.npy\")  # assuming consistent labels\n",
    "\n",
    "# Check dimensions\n",
    "print(\"MobileNet features:\", mobilenet_features.shape)\n",
    "print(\"DenseNet features:\", densenet_features.shape)\n",
    "print(\"Manual features:\", manual_features.shape)\n",
    "print(\"Labels:\", labels.shape)\n",
    "\n",
    "# Concatenate features\n",
    "combined_features = np.hstack((mobilenet_features, densenet_features, manual_features))\n",
    "print(\"Combined feature shape:\", combined_features.shape)\n",
    "\n",
    "# Handle missing values\n",
    "imputer = SimpleImputer(strategy='mean')\n",
    "combined_features = imputer.fit_transform(combined_features)\n",
    "\n",
    "# Normalize features\n",
    "scaler = StandardScaler()\n",
    "combined_features = scaler.fit_transform(combined_features)\n",
    "\n",
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    combined_features, labels, test_size=0.2, random_state=42, stratify=labels\n",
    ")\n",
    "\n",
    "# Train Logistic Regression\n",
    "model = LogisticRegression(max_iter=1000)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Predict and evaluate\n",
    "y_pred = model.predict(X_test)\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(\"Logistic Regression Accuracy:\", accuracy_score(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "96809fb7-56d2-4ded-ae0a-0aca586a17d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:07:55] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "D:\\Anaconda\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:24:41] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "D:\\Anaconda\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:26:50] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "D:\\Anaconda\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:28:49] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "D:\\Anaconda\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:30:51] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "D:\\Anaconda\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:32:46] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Stacked Model]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.72      0.69       300\n",
      "           1       0.94      0.94      0.94       200\n",
      "           2       0.65      0.56      0.60       252\n",
      "           3       0.88      0.88      0.88       200\n",
      "           4       0.92      0.92      0.92       200\n",
      "           5       0.70      0.67      0.68       300\n",
      "           6       0.62      0.67      0.65       300\n",
      "\n",
      "    accuracy                           0.75      1752\n",
      "   macro avg       0.77      0.76      0.77      1752\n",
      "weighted avg       0.75      0.75      0.74      1752\n",
      "\n",
      "Stacked Accuracy: 0.7454337899543378\n"
     ]
    }
   ],
   "source": [
    "#MobileNet+Densenet+Manual On Stacked CLassifeirs\n",
    "\n",
    "from sklearn.ensemble import StackingClassifier\n",
    "import numpy as np\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "# Load features\n",
    "mobilenet= np.load(\"oversampled_featuresets/ovs_mobilenet_features.npy\")\n",
    "densenet= np.load(\"oversampled_featuresets/ovs_densenet_features.npy\")\n",
    "manual= np.load(\"oversampled_featuresets/ovs_manual_features.npy\")\n",
    "labels = np.load(\"oversampled_featuresets/ovs_resnet_labels.npy\")  # assuming consistent labels\n",
    "\n",
    "# Combine features\n",
    "combined = np.hstack((mobilenet, densenet, manual))\n",
    "\n",
    "# Handle missing values\n",
    "imputer = SimpleImputer(strategy=\"mean\")\n",
    "combined = imputer.fit_transform(combined)\n",
    "\n",
    "# Scale\n",
    "scaler = StandardScaler()\n",
    "combined = scaler.fit_transform(combined)\n",
    "\n",
    "# Split\n",
    "X_train, X_test, y_train, y_test = train_test_split(combined, labels, test_size=0.2, random_state=42, stratify=labels)\n",
    "\n",
    "# Define base learners\n",
    "base_learners = [\n",
    "    ('svm', SVC(probability=True, random_state=42)),\n",
    "    ('xgb', XGBClassifier(use_label_encoder=False, eval_metric='mlogloss', random_state=42)),\n",
    "    ('lr', LogisticRegression(max_iter=1000, random_state=42))\n",
    "]\n",
    "\n",
    "# Meta-learner\n",
    "meta_learner = LogisticRegression(max_iter=1000, random_state=42)\n",
    "\n",
    "# Stacking classifier\n",
    "stacked_model = StackingClassifier(estimators=base_learners, final_estimator=meta_learner, cv=5)\n",
    "\n",
    "# Train and evaluate\n",
    "stacked_model.fit(X_train, y_train)\n",
    "y_pred = stacked_model.predict(X_test)\n",
    "\n",
    "print(\"\\n[Stacked Model]\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(\"Stacked Accuracy:\", accuracy_score(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "33efd5dd-c37a-4274-85d3-e3096cb8794b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ResNet features: (8757, 2048)\n",
      "MobileNet features: (8757, 1280)\n",
      "Manual features: (8757, 18)\n",
      "Labels: (8757,)\n",
      "Combined feature shape: (8757, 3346)\n"
     ]
    }
   ],
   "source": [
    "#ResNet + MobilevNet + Manual\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "# Load features and labels\n",
    "resnet_features = np.load(\"oversampled_featuresets/ovs_resnet_features.npy\")\n",
    "mobilenet_features = np.load(\"oversampled_featuresets/ovs_mobilenet_features.npy\")\n",
    "manual_features = np.load(\"oversampled_featuresets/ovs_manual_features.npy\")\n",
    "labels = np.load(\"oversampled_featuresets/ovs_resnet_labels.npy\")\n",
    "\n",
    "# Check dimensions\n",
    "print(\"ResNet features:\", resnet_features.shape)\n",
    "print(\"MobileNet features:\", mobilenet_features.shape)\n",
    "print(\"Manual features:\", manual_features.shape)\n",
    "print(\"Labels:\", labels.shape)\n",
    "\n",
    "# Concatenate features\n",
    "combined_features = np.hstack((resnet_features, mobilenet_features, manual_features))\n",
    "print(\"Combined feature shape:\", combined_features.shape)\n",
    "\n",
    "# Handle missing values\n",
    "imputer = SimpleImputer(strategy=\"mean\")\n",
    "combined_features = imputer.fit_transform(combined_features)\n",
    "\n",
    "# Scale\n",
    "scaler = StandardScaler()\n",
    "combined_features = scaler.fit_transform(combined_features)\n",
    "\n",
    "# Split\n",
    "X_train, X_test, y_train, y_test = train_test_split(combined_features, labels, test_size=0.2, random_state=42, stratify=labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "df993bc5-eb63-4781-ab38-5cc90ca4f3ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[SVM]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.68      0.66       300\n",
      "           1       0.88      0.83      0.86       200\n",
      "           2       0.63      0.48      0.55       252\n",
      "           3       0.79      0.81      0.80       200\n",
      "           4       0.87      0.90      0.88       200\n",
      "           5       0.64      0.65      0.64       300\n",
      "           6       0.59      0.65      0.62       300\n",
      "\n",
      "    accuracy                           0.70      1752\n",
      "   macro avg       0.72      0.71      0.71      1752\n",
      "weighted avg       0.70      0.70      0.70      1752\n",
      "\n",
      "Accuracy: 0.6980593607305936\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "model = SVC()\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "print(\"\\n[SVM]\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0bca8879-559a-4b42-afcb-2858e6075c34",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:37:26] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[XGBoost]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.69      0.65       300\n",
      "           1       0.87      0.90      0.89       200\n",
      "           2       0.57      0.45      0.50       252\n",
      "           3       0.83      0.80      0.81       200\n",
      "           4       0.87      0.87      0.87       200\n",
      "           5       0.63      0.64      0.64       300\n",
      "           6       0.57      0.59      0.58       300\n",
      "\n",
      "    accuracy                           0.69      1752\n",
      "   macro avg       0.71      0.71      0.71      1752\n",
      "weighted avg       0.69      0.69      0.69      1752\n",
      "\n",
      "Accuracy: 0.6883561643835616\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "\n",
    "model = XGBClassifier(use_label_encoder=False, eval_metric='mlogloss', random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "print(\"\\n[XGBoost]\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9c80b519-5c86-418c-87d3-98f51d4eec07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ResNet features: (8757, 2048)\n",
      "DenseNet features: (8757, 1024)\n",
      "Manual features: (8757, 18)\n",
      "Labels: (8757,)\n",
      "Combined feature shape: (8757, 3090)\n"
     ]
    }
   ],
   "source": [
    "# ResNet + DenseNet + Manaul\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "# Load features and labels\n",
    "resnet_features = np.load(\"oversampled_featuresets/ovs_resnet_features.npy\")\n",
    "densenet_features = np.load(\"oversampled_featuresets/ovs_densenet_features.npy\")\n",
    "manual_features = np.load(\"oversampled_featuresets/ovs_manual_features.npy\")\n",
    "labels = np.load(\"oversampled_featuresets/ovs_resnet_labels.npy\")\n",
    "\n",
    "# Check dimensions\n",
    "print(\"ResNet features:\", resnet_features.shape)\n",
    "print(\"DenseNet features:\", densenet_features.shape)\n",
    "print(\"Manual features:\", manual_features.shape)\n",
    "print(\"Labels:\", labels.shape)\n",
    "\n",
    "# Combine features\n",
    "combined_features = np.hstack((resnet_features, densenet_features, manual_features))\n",
    "print(\"Combined feature shape:\", combined_features.shape)\n",
    "\n",
    "# Handle missing values\n",
    "imputer = SimpleImputer(strategy=\"mean\")\n",
    "combined_features = imputer.fit_transform(combined_features)\n",
    "\n",
    "# Normalize\n",
    "scaler = StandardScaler()\n",
    "combined_features = scaler.fit_transform(combined_features)\n",
    "\n",
    "# Split data\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    combined_features, labels, test_size=0.2, random_state=42, stratify=labels\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d07a54b9-b6c9-48a5-a6d5-04f81a92747a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:47:09] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[XGBoost]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.59      0.63      0.61       300\n",
      "           1       0.89      0.89      0.89       200\n",
      "           2       0.49      0.39      0.44       252\n",
      "           3       0.83      0.81      0.82       200\n",
      "           4       0.84      0.86      0.85       200\n",
      "           5       0.58      0.62      0.60       300\n",
      "           6       0.50      0.53      0.51       300\n",
      "\n",
      "    accuracy                           0.65      1752\n",
      "   macro avg       0.68      0.68      0.68      1752\n",
      "weighted avg       0.65      0.65      0.65      1752\n",
      "\n",
      "Accuracy: 0.6535388127853882\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "\n",
    "model = XGBClassifier(use_label_encoder=False, eval_metric='mlogloss', random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "print(\"\\n[XGBoost]\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8a337473-5f99-4a0f-8f40-0c0250fc5521",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[SVM]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.64      0.63       300\n",
      "           1       0.87      0.88      0.88       200\n",
      "           2       0.61      0.41      0.49       252\n",
      "           3       0.81      0.80      0.81       200\n",
      "           4       0.85      0.84      0.85       200\n",
      "           5       0.57      0.65      0.61       300\n",
      "           6       0.55      0.62      0.58       300\n",
      "\n",
      "    accuracy                           0.67      1752\n",
      "   macro avg       0.70      0.69      0.69      1752\n",
      "weighted avg       0.68      0.67      0.67      1752\n",
      "\n",
      "Accuracy: 0.6735159817351598\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "model = SVC()\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "print(\"\\n[SVM]\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "bb917384-a579-4c7c-9dfe-8e9563f53a38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ResNet: (8757, 2048)\n",
      "DenseNet: (8757, 1024)\n",
      "MobileNet: (8757, 1280)\n",
      "Manual: (8757, 18)\n",
      "Labels: (8757,)\n",
      "Combined shape: (8757, 4370)\n"
     ]
    }
   ],
   "source": [
    "#ResNet + DenseNet + MobilevNet + Manual\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "# Load features and labels\n",
    "resnet = np.load(\"oversampled_featuresets/ovs_resnet_features.npy\")\n",
    "densenet = np.load(\"oversampled_featuresets/ovs_densenet_features.npy\")\n",
    "mobilenet = np.load(\"oversampled_featuresets/ovs_mobilenet_features.npy\")\n",
    "manual = np.load(\"oversampled_featuresets/ovs_manual_features.npy\")\n",
    "labels = np.load(\"oversampled_featuresets/ovs_resnet_labels.npy\")\n",
    "\n",
    "# Check shapes\n",
    "print(\"ResNet:\", resnet.shape)\n",
    "print(\"DenseNet:\", densenet.shape)\n",
    "print(\"MobileNet:\", mobilenet.shape)\n",
    "print(\"Manual:\", manual.shape)\n",
    "print(\"Labels:\", labels.shape)\n",
    "\n",
    "# Combine features\n",
    "combined = np.hstack((resnet, densenet, mobilenet, manual))\n",
    "print(\"Combined shape:\", combined.shape)\n",
    "\n",
    "# Handle NaNs\n",
    "imputer = SimpleImputer(strategy=\"mean\")\n",
    "combined = imputer.fit_transform(combined)\n",
    "\n",
    "# Normalize\n",
    "scaler = StandardScaler()\n",
    "combined = scaler.fit_transform(combined)\n",
    "\n",
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    combined, labels, test_size=0.2, random_state=42, stratify=labels\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "306c317a-7486-4ea9-9455-027ad2013743",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [00:57:06] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[XGBoost]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.66      0.63       300\n",
      "           1       0.87      0.94      0.90       200\n",
      "           2       0.60      0.48      0.54       252\n",
      "           3       0.86      0.81      0.83       200\n",
      "           4       0.87      0.86      0.87       200\n",
      "           5       0.65      0.66      0.66       300\n",
      "           6       0.58      0.63      0.60       300\n",
      "\n",
      "    accuracy                           0.70      1752\n",
      "   macro avg       0.72      0.72      0.72      1752\n",
      "weighted avg       0.70      0.70      0.70      1752\n",
      "\n",
      "Accuracy: 0.6997716894977168\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "\n",
    "model = XGBClassifier(use_label_encoder=False, eval_metric='mlogloss', random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "print(\"\\n[XGBoost]\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "042e6976-7bf6-4aac-9749-08dec498c8cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[SVM]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.68      0.66       300\n",
      "           1       0.90      0.90      0.90       200\n",
      "           2       0.63      0.50      0.56       252\n",
      "           3       0.83      0.82      0.83       200\n",
      "           4       0.87      0.90      0.88       200\n",
      "           5       0.64      0.65      0.64       300\n",
      "           6       0.60      0.65      0.62       300\n",
      "\n",
      "    accuracy                           0.71      1752\n",
      "   macro avg       0.73      0.73      0.73      1752\n",
      "weighted avg       0.71      0.71      0.71      1752\n",
      "\n",
      "Accuracy: 0.7094748858447488\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "model = SVC()\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "print(\"\\n[SVM]\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37aa623d-f2c0-44f1-8120-23cf769fe4b4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
