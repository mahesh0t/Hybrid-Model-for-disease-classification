{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "67016e81-1cb3-4c3d-b98f-86c903f00b75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ” Augmenting class: 1. Eczema\n",
      "\n",
      "ðŸ” Augmenting class: 3. Atopic Dermatitis\n",
      "\n",
      "ðŸ” Augmenting class: 6. Fungal Infections\n",
      "\n",
      "ðŸ” Augmenting class: 7. Viral Infections\n",
      "\n",
      "Train/Test split complete.\n",
      " Training set in: Split_IMG_CLASSES/train\n",
      " Testing set in: Split_IMG_CLASSES/test\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "import random\n",
    "import cv2\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from imgaug import augmenters as iaa\n",
    "\n",
    "# INPUT: your resized dataset\n",
    "input_dir = \"Resized_IMG_CLASSES\"\n",
    "train_dir = \"Split_IMG_CLASSES/train\"\n",
    "test_dir = \"Split_IMG_CLASSES/test\"\n",
    "classes_to_augment = [\"1. Eczema\", \"3. Atopic Dermatitis\", \"6. Fungal Infections\", \"7. Viral Infections\"]\n",
    "target_augmented_count = 1500\n",
    "test_split_ratio = 0.2\n",
    "\n",
    "# Mild augmentation sequence\n",
    "augmenter = iaa.Sequential([\n",
    "    iaa.Fliplr(0.3),\n",
    "    iaa.LinearContrast((0.9, 1.1)),\n",
    "    iaa.AdditiveGaussianNoise(scale=(0, 0.02 * 255))\n",
    "])\n",
    "\n",
    "# Prepare folders\n",
    "for base in [train_dir, test_dir]:\n",
    "    os.makedirs(base, exist_ok=True)\n",
    "\n",
    "# Split and optionally augment\n",
    "for class_name in os.listdir(input_dir):\n",
    "    class_path = os.path.join(input_dir, class_name)\n",
    "    if not os.path.isdir(class_path):\n",
    "        continue\n",
    "\n",
    "    images = [img for img in os.listdir(class_path) if img.lower().endswith(('.jpg', '.png', '.jpeg'))]\n",
    "    random.shuffle(images)\n",
    "    split_idx = int(len(images) * (1 - test_split_ratio))\n",
    "\n",
    "    train_images = images[:split_idx]\n",
    "    test_images = images[split_idx:]\n",
    "\n",
    "    # Create train/test subfolders\n",
    "    os.makedirs(os.path.join(train_dir, class_name), exist_ok=True)\n",
    "    os.makedirs(os.path.join(test_dir, class_name), exist_ok=True)\n",
    "\n",
    "    # Copy test images\n",
    "    for img in test_images:\n",
    "        src = os.path.join(class_path, img)\n",
    "        dst = os.path.join(test_dir, class_name, img)\n",
    "        shutil.copy2(src, dst)\n",
    "\n",
    "    # Copy and augment training images\n",
    "    for img in train_images:\n",
    "        src = os.path.join(class_path, img)\n",
    "        dst = os.path.join(train_dir, class_name, img)\n",
    "        shutil.copy2(src, dst)\n",
    "\n",
    "    if class_name in classes_to_augment:\n",
    "        print(f\"\\nðŸ” Augmenting class: {class_name}\")\n",
    "        current_images = os.listdir(os.path.join(train_dir, class_name))\n",
    "        needed = target_augmented_count - len(current_images)\n",
    "        if needed > 0:\n",
    "            idx = 0\n",
    "            while len(os.listdir(os.path.join(train_dir, class_name))) < target_augmented_count:\n",
    "                img_name = train_images[idx % len(train_images)]\n",
    "                img_path = os.path.join(class_path, img_name)\n",
    "                image = cv2.imread(img_path)\n",
    "\n",
    "                if image is None:\n",
    "                    idx += 1\n",
    "                    continue\n",
    "\n",
    "                image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "                aug_img = augmenter(image=image)\n",
    "                aug_img = cv2.cvtColor(aug_img, cv2.COLOR_RGB2BGR)\n",
    "\n",
    "                aug_name = f\"aug_{idx}_{img_name}\"\n",
    "                aug_path = os.path.join(train_dir, class_name, aug_name)\n",
    "                cv2.imwrite(aug_path, aug_img)\n",
    "\n",
    "                idx += 1\n",
    "\n",
    "print(\"\\nTrain/Test split complete.\")\n",
    "print(f\" Training set in: {train_dir}\")\n",
    "print(f\" Testing set in: {test_dir}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "684919d8-a327-49a0-89b6-13fb26d72dd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1. Eczema: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1500/1500 [00:20<00:00, 74.97it/s]\n",
      "2. Melanoma: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 800/800 [00:10<00:00, 75.30it/s]\n",
      "3. Atopic Dermatitis: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1500/1500 [00:19<00:00, 76.44it/s]\n",
      "4. Melanocytic Nevi: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 800/800 [00:10<00:00, 76.57it/s]\n",
      "5. Benign Keratosis: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 800/800 [00:10<00:00, 76.10it/s]\n",
      "6. Fungal Infections: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1500/1500 [00:19<00:00, 75.13it/s]\n",
      "7. Viral Infections: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1500/1500 [00:19<00:00, 75.69it/s]\n",
      "1. Eczema: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 200/200 [00:02<00:00, 73.89it/s]\n",
      "2. Melanoma: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 200/200 [00:02<00:00, 75.42it/s]\n",
      "3. Atopic Dermatitis: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 200/200 [00:02<00:00, 74.88it/s]\n",
      "4. Melanocytic Nevi: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 200/200 [00:02<00:00, 71.54it/s]\n",
      "5. Benign Keratosis: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 200/200 [00:02<00:00, 75.19it/s]\n",
      "6. Fungal Infections: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 200/200 [00:02<00:00, 73.82it/s]\n",
      "7. Viral Infections: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 200/200 [00:02<00:00, 77.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Manual feature extraction complete and saved.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import cv2\n",
    "from tqdm import tqdm\n",
    "from skimage.feature import local_binary_pattern, graycomatrix, graycoprops\n",
    "from skimage.color import rgb2gray\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "def extract_lbp(image):\n",
    "    gray = rgb2gray(image)\n",
    "    lbp = local_binary_pattern((gray * 255).astype(np.uint8), P=8, R=1, method='uniform')\n",
    "    hist, _ = np.histogram(lbp.ravel(), bins=np.arange(0, 11), range=(0, 10))\n",
    "    return hist.astype(np.float32)\n",
    "\n",
    "def extract_glcm(image):\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)\n",
    "    glcm = graycomatrix(gray, distances=[1], angles=[0], levels=256, symmetric=True, normed=True)\n",
    "    contrast = graycoprops(glcm, 'contrast')[0, 0]\n",
    "    dissimilarity = graycoprops(glcm, 'dissimilarity')[0, 0]\n",
    "    homogeneity = graycoprops(glcm, 'homogeneity')[0, 0]\n",
    "    energy = graycoprops(glcm, 'energy')[0, 0]\n",
    "    return np.array([contrast, dissimilarity, homogeneity, energy])\n",
    "\n",
    "def extract_manual_features_from_folder(base_dir):\n",
    "    features = []\n",
    "    labels = []\n",
    "    class_names = sorted(os.listdir(base_dir))\n",
    "    for label_index, class_name in enumerate(class_names):\n",
    "        class_path = os.path.join(base_dir, class_name)\n",
    "        for img_name in tqdm(os.listdir(class_path), desc=class_name):\n",
    "            img_path = os.path.join(class_path, img_name)\n",
    "            image = cv2.imread(img_path)\n",
    "            if image is None:\n",
    "                continue\n",
    "            image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "            image = cv2.resize(image, (224, 224))\n",
    "            lbp_feat = extract_lbp(image)\n",
    "            glcm_feat = extract_glcm(image)\n",
    "            combined = np.hstack([lbp_feat, glcm_feat])\n",
    "            features.append(combined)\n",
    "            labels.append(label_index)\n",
    "    return np.array(features), np.array(labels)\n",
    "\n",
    "# Extract manual features\n",
    "train_manual, train_labels = extract_manual_features_from_folder(\"Split_IMG_CLASSES/train\")\n",
    "test_manual, test_labels = extract_manual_features_from_folder(\"Split_IMG_CLASSES/test\")\n",
    "\n",
    "# Normalize\n",
    "scaler = StandardScaler()\n",
    "train_manual_scaled = scaler.fit_transform(train_manual)\n",
    "import pickle\n",
    "\n",
    "# Save the fitted scaler\n",
    "with open(\"scaler.pkl\", \"wb\") as f:\n",
    "    pickle.dump(scaler, f)\n",
    "test_manual_scaled = scaler.transform(test_manual)\n",
    "\n",
    "# Save\n",
    "np.save(\"featuresets/train_manual_features.npy\", train_manual_scaled)\n",
    "np.save(\"featuresets/test_manual_features.npy\", test_manual_scaled)\n",
    "np.save(\"featuresets/train_manual_labels.npy\", train_labels)\n",
    "np.save(\"featuresets/test_manual_labels.npy\", test_labels)\n",
    "\n",
    "print(\"\\nManual feature extraction complete and saved.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c6dabcc2-ea92-4be2-a8d0-ef87099ed983",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\RYZEN\\AppData\\Local\\Temp\\ipykernel_28332\\2111761863.py:11: UserWarning: `input_shape` is undefined or non-square, or `rows` is not in [96, 128, 160, 192, 224]. Weights for input shape (224, 224) will be loaded as the default.\n",
      "  base_model = MobileNetV2(weights='imagenet', include_top=False, pooling='avg')\n",
      "1. Eczema: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1500/1500 [02:10<00:00, 11.45it/s]\n",
      "2. Melanoma: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 800/800 [01:09<00:00, 11.52it/s]\n",
      "3. Atopic Dermatitis: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1500/1500 [02:10<00:00, 11.49it/s]\n",
      "4. Melanocytic Nevi: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 800/800 [01:09<00:00, 11.53it/s]\n",
      "5. Benign Keratosis: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 800/800 [01:09<00:00, 11.52it/s]\n",
      "6. Fungal Infections: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1500/1500 [02:11<00:00, 11.43it/s]\n",
      "7. Viral Infections: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1500/1500 [02:13<00:00, 11.27it/s]\n",
      "1. Eczema: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 200/200 [00:17<00:00, 11.17it/s]\n",
      "2. Melanoma: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 200/200 [00:17<00:00, 11.32it/s]\n",
      "3. Atopic Dermatitis: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 200/200 [00:18<00:00, 10.69it/s]\n",
      "4. Melanocytic Nevi: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 200/200 [00:17<00:00, 11.36it/s]\n",
      "5. Benign Keratosis: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 200/200 [00:18<00:00, 11.10it/s]\n",
      "6. Fungal Infections: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 200/200 [00:17<00:00, 11.21it/s]\n",
      "7. Viral Infections: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 200/200 [00:17<00:00, 11.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " MobileNetV2 features extracted and saved.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import cv2\n",
    "from tqdm import tqdm\n",
    "from tensorflow.keras.applications import MobileNetV2\n",
    "from tensorflow.keras.applications.mobilenet_v2 import preprocess_input as mobilenet_preprocess\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.preprocessing import image\n",
    "\n",
    "# Load MobileNetV2 model\n",
    "base_model = MobileNetV2(weights='imagenet', include_top=False, pooling='avg')\n",
    "model = Model(inputs=base_model.input, outputs=base_model.output)\n",
    "\n",
    "def extract_deep_features(base_dir, model, preprocess_func):\n",
    "    features = []\n",
    "    labels = []\n",
    "    class_names = sorted(os.listdir(base_dir))\n",
    "    for label_index, class_name in enumerate(class_names):\n",
    "        class_path = os.path.join(base_dir, class_name)\n",
    "        for img_name in tqdm(os.listdir(class_path), desc=f\"{class_name}\"):\n",
    "            img_path = os.path.join(class_path, img_name)\n",
    "            img = cv2.imread(img_path)\n",
    "            if img is None:\n",
    "                continue\n",
    "            img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "            img = cv2.resize(img, (224, 224))\n",
    "            img_array = image.img_to_array(img)\n",
    "            img_array = np.expand_dims(img_array, axis=0)\n",
    "            img_array = preprocess_func(img_array)\n",
    "            feat = model.predict(img_array, verbose=0)\n",
    "            features.append(feat.flatten())\n",
    "            labels.append(label_index)\n",
    "    return np.array(features), np.array(labels)\n",
    "\n",
    "# Extract MobileNetV2 features\n",
    "mobilenet_train, mobilenet_train_labels = extract_deep_features(\"Split_IMG_CLASSES/train\", model, mobilenet_preprocess)\n",
    "mobilenet_test, mobilenet_test_labels = extract_deep_features(\"Split_IMG_CLASSES/test\", model, mobilenet_preprocess)\n",
    "\n",
    "# Save\n",
    "np.save(\"featuresets/train_mobilenet_features.npy\", mobilenet_train)\n",
    "np.save(\"featuresets/test_mobilenet_features.npy\", mobilenet_test)\n",
    "np.save(\"featuresets/train_mobilenet_labels.npy\", mobilenet_train_labels)\n",
    "np.save(\"featuresets/test_mobilenet_labels.npy\", mobilenet_test_labels)\n",
    "\n",
    "print(\"\\n MobileNetV2 features extracted and saved.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "96c0e259-3db7-4af3-8d97-d3a35f9c2385",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/densenet/densenet121_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "\u001b[1m29084464/29084464\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 1us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1. Eczema: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1500/1500 [03:28<00:00,  7.21it/s]\n",
      "2. Melanoma: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 800/800 [01:45<00:00,  7.57it/s]\n",
      "3. Atopic Dermatitis: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1500/1500 [03:26<00:00,  7.27it/s]\n",
      "4. Melanocytic Nevi: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 800/800 [01:51<00:00,  7.17it/s]\n",
      "5. Benign Keratosis: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 800/800 [01:51<00:00,  7.21it/s]\n",
      "6. Fungal Infections: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1500/1500 [03:26<00:00,  7.25it/s]\n",
      "7. Viral Infections: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1500/1500 [03:24<00:00,  7.33it/s]\n",
      "1. Eczema: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 200/200 [00:27<00:00,  7.28it/s]\n",
      "2. Melanoma: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 200/200 [00:28<00:00,  7.13it/s]\n",
      "3. Atopic Dermatitis: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 200/200 [00:27<00:00,  7.35it/s]\n",
      "4. Melanocytic Nevi: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 200/200 [00:27<00:00,  7.25it/s]\n",
      "5. Benign Keratosis: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 200/200 [00:27<00:00,  7.34it/s]\n",
      "6. Fungal Infections: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 200/200 [00:27<00:00,  7.35it/s]\n",
      "7. Viral Infections: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 200/200 [00:26<00:00,  7.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " DenseNet121 features extracted and saved.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import cv2\n",
    "from tqdm import tqdm\n",
    "from tensorflow.keras.applications import DenseNet121\n",
    "from tensorflow.keras.applications.densenet import preprocess_input as densenet_preprocess\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.preprocessing import image\n",
    "\n",
    "# Load DenseNet121 model (without top layer, with global average pooling)\n",
    "base_model = DenseNet121(weights='imagenet', include_top=False, pooling='avg')\n",
    "model = Model(inputs=base_model.input, outputs=base_model.output)\n",
    "\n",
    "def extract_deep_features(base_dir, model, preprocess_func):\n",
    "    features = []\n",
    "    labels = []\n",
    "    class_names = sorted(os.listdir(base_dir))\n",
    "    for label_index, class_name in enumerate(class_names):\n",
    "        class_path = os.path.join(base_dir, class_name)\n",
    "        for img_name in tqdm(os.listdir(class_path), desc=f\"{class_name}\"):\n",
    "            img_path = os.path.join(class_path, img_name)\n",
    "            img = cv2.imread(img_path)\n",
    "            if img is None:\n",
    "                continue\n",
    "            img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "            img = cv2.resize(img, (224, 224))\n",
    "            img_array = image.img_to_array(img)\n",
    "            img_array = np.expand_dims(img_array, axis=0)\n",
    "            img_array = preprocess_func(img_array)\n",
    "            feat = model.predict(img_array, verbose=0)\n",
    "            features.append(feat.flatten())\n",
    "            labels.append(label_index)\n",
    "    return np.array(features), np.array(labels)\n",
    "\n",
    "# Extract DenseNet features\n",
    "densenet_train, densenet_train_labels = extract_deep_features(\"Split_IMG_CLASSES/train\", model, densenet_preprocess)\n",
    "densenet_test, densenet_test_labels = extract_deep_features(\"Split_IMG_CLASSES/test\", model, densenet_preprocess)\n",
    "\n",
    "# Save\n",
    "np.save(\"featuresets/train_densenet_features.npy\", densenet_train)\n",
    "np.save(\"featuresets/test_densenet_features.npy\", densenet_test)\n",
    "np.save(\"featuresets/train_densenet_labels.npy\", densenet_train_labels)\n",
    "np.save(\"featuresets/test_densenet_labels.npy\", densenet_test_labels)\n",
    "\n",
    "print(\"\\n DenseNet121 features extracted and saved.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0568078f-75d8-46c6-a04f-b1bf7adc8f8b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
