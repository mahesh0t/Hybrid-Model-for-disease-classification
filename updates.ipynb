{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6e1cb33-9e24-4260-a0fa-6a41457fb78b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import random\n",
    "import cv2\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from imgaug import augmenters as iaa\n",
    "\n",
    "# INPUT: your resized dataset\n",
    "input_dir = \"Resized_IMG_CLASSES\"\n",
    "train_dir = \"Split_IMG_CLASSES/train\"\n",
    "test_dir = \"Split_IMG_CLASSES/test\"\n",
    "classes_to_augment = [\"1. Eczema\", \"3. Atopic Dermatitis\", \"6. Fungal Infections\", \"7. Viral Infections\"]\n",
    "target_augmented_count = 1500\n",
    "test_split_ratio = 0.2\n",
    "\n",
    "# Mild augmentation sequence\n",
    "augmenter = iaa.Sequential([\n",
    "    iaa.Fliplr(0.3),\n",
    "    iaa.LinearContrast((0.9, 1.1)),\n",
    "    iaa.AdditiveGaussianNoise(scale=(0, 0.02 * 255))\n",
    "])\n",
    "\n",
    "# Prepare folders\n",
    "for base in [train_dir, test_dir]:\n",
    "    os.makedirs(base, exist_ok=True)\n",
    "\n",
    "# Split and optionally augment\n",
    "for class_name in os.listdir(input_dir):\n",
    "    class_path = os.path.join(input_dir, class_name)\n",
    "    if not os.path.isdir(class_path):\n",
    "        continue\n",
    "\n",
    "    images = [img for img in os.listdir(class_path) if img.lower().endswith(('.jpg', '.png', '.jpeg'))]\n",
    "    random.shuffle(images)\n",
    "    split_idx = int(len(images) * (1 - test_split_ratio))\n",
    "\n",
    "    train_images = images[:split_idx]\n",
    "    test_images = images[split_idx:]\n",
    "\n",
    "    # Create train/test subfolders\n",
    "    os.makedirs(os.path.join(train_dir, class_name), exist_ok=True)\n",
    "    os.makedirs(os.path.join(test_dir, class_name), exist_ok=True)\n",
    "\n",
    "    # Copy test images\n",
    "    for img in test_images:\n",
    "        src = os.path.join(class_path, img)\n",
    "        dst = os.path.join(test_dir, class_name, img)\n",
    "        shutil.copy2(src, dst)\n",
    "\n",
    "    # Copy and augment training images\n",
    "    for img in train_images:\n",
    "        src = os.path.join(class_path, img)\n",
    "        dst = os.path.join(train_dir, class_name, img)\n",
    "        shutil.copy2(src, dst)\n",
    "\n",
    "    if class_name in classes_to_augment:\n",
    "        print(f\"\\n🔁 Augmenting class: {class_name}\")\n",
    "        current_images = os.listdir(os.path.join(train_dir, class_name))\n",
    "        needed = target_augmented_count - len(current_images)\n",
    "        if needed > 0:\n",
    "            idx = 0\n",
    "            while len(os.listdir(os.path.join(train_dir, class_name))) < target_augmented_count:\n",
    "                img_name = train_images[idx % len(train_images)]\n",
    "                img_path = os.path.join(class_path, img_name)\n",
    "                image = cv2.imread(img_path)\n",
    "\n",
    "                if image is None:\n",
    "                    idx += 1\n",
    "                    continue\n",
    "\n",
    "                image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "                aug_img = augmenter(image=image)\n",
    "                aug_img = cv2.cvtColor(aug_img, cv2.COLOR_RGB2BGR)\n",
    "\n",
    "                aug_name = f\"aug_{idx}_{img_name}\"\n",
    "                aug_path = os.path.join(train_dir, class_name, aug_name)\n",
    "                cv2.imwrite(aug_path, aug_img)\n",
    "\n",
    "                idx += 1\n",
    "\n",
    "print(\"\\nTrain/Test split complete.\")\n",
    "print(f\" Training set in: {train_dir}\")\n",
    "print(f\" Testing set in: {test_dir}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5bd8837-eecc-471e-afa8-3c7603948ec4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import cv2\n",
    "from tqdm import tqdm\n",
    "from skimage.feature import local_binary_pattern, graycomatrix, graycoprops\n",
    "from skimage.color import rgb2gray\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "def extract_lbp(image):\n",
    "    gray = rgb2gray(image)\n",
    "    lbp = local_binary_pattern((gray * 255).astype(np.uint8), P=8, R=1, method='uniform')\n",
    "    hist, _ = np.histogram(lbp.ravel(), bins=np.arange(0, 11), range=(0, 10))\n",
    "    return hist.astype(np.float32)\n",
    "\n",
    "def extract_glcm(image):\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)\n",
    "    glcm = graycomatrix(gray, distances=[1], angles=[0], levels=256, symmetric=True, normed=True)\n",
    "    contrast = graycoprops(glcm, 'contrast')[0, 0]\n",
    "    dissimilarity = graycoprops(glcm, 'dissimilarity')[0, 0]\n",
    "    homogeneity = graycoprops(glcm, 'homogeneity')[0, 0]\n",
    "    energy = graycoprops(glcm, 'energy')[0, 0]\n",
    "    return np.array([contrast, dissimilarity, homogeneity, energy])\n",
    "\n",
    "def extract_manual_features_from_folder(base_dir):\n",
    "    features = []\n",
    "    labels = []\n",
    "    class_names = sorted(os.listdir(base_dir))\n",
    "    for label_index, class_name in enumerate(class_names):\n",
    "        class_path = os.path.join(base_dir, class_name)\n",
    "        for img_name in tqdm(os.listdir(class_path), desc=class_name):\n",
    "            img_path = os.path.join(class_path, img_name)\n",
    "            image = cv2.imread(img_path)\n",
    "            if image is None:\n",
    "                continue\n",
    "            image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "            image = cv2.resize(image, (224, 224))\n",
    "            lbp_feat = extract_lbp(image)\n",
    "            glcm_feat = extract_glcm(image)\n",
    "            combined = np.hstack([lbp_feat, glcm_feat])\n",
    "            features.append(combined)\n",
    "            labels.append(label_index)\n",
    "    return np.array(features), np.array(labels)\n",
    "\n",
    "# Extract manual features\n",
    "train_manual, train_labels = extract_manual_features_from_folder(\"Split_IMG_CLASSES/train\")\n",
    "test_manual, test_labels = extract_manual_features_from_folder(\"Split_IMG_CLASSES/test\")\n",
    "\n",
    "# Normalize\n",
    "scaler = StandardScaler()\n",
    "train_manual_scaled = scaler.fit_transform(train_manual)\n",
    "test_manual_scaled = scaler.transform(test_manual)\n",
    "\n",
    "# Save\n",
    "np.save(\"featuresets/train_manual_features.npy\", train_manual_scaled)\n",
    "np.save(\"featuresets/test_manual_features.npy\", test_manual_scaled)\n",
    "np.save(\"featuresets/train_manual_labels.npy\", train_labels)\n",
    "np.save(\"featuresets/test_manual_labels.npy\", test_labels)\n",
    "\n",
    "print(\"\\nManual feature extraction complete and saved.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e48f342b-4ae7-42b8-8ad9-a9f944c8096d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import cv2\n",
    "from tqdm import tqdm\n",
    "from tensorflow.keras.applications import MobileNetV2\n",
    "from tensorflow.keras.applications.mobilenet_v2 import preprocess_input as mobilenet_preprocess\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.preprocessing import image\n",
    "\n",
    "# Load MobileNetV2 model\n",
    "base_model = MobileNetV2(weights='imagenet', include_top=False, pooling='avg')\n",
    "model = Model(inputs=base_model.input, outputs=base_model.output)\n",
    "\n",
    "def extract_deep_features(base_dir, model, preprocess_func):\n",
    "    features = []\n",
    "    labels = []\n",
    "    class_names = sorted(os.listdir(base_dir))\n",
    "    for label_index, class_name in enumerate(class_names):\n",
    "        class_path = os.path.join(base_dir, class_name)\n",
    "        for img_name in tqdm(os.listdir(class_path), desc=f\"{class_name}\"):\n",
    "            img_path = os.path.join(class_path, img_name)\n",
    "            img = cv2.imread(img_path)\n",
    "            if img is None:\n",
    "                continue\n",
    "            img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "            img = cv2.resize(img, (224, 224))\n",
    "            img_array = image.img_to_array(img)\n",
    "            img_array = np.expand_dims(img_array, axis=0)\n",
    "            img_array = preprocess_func(img_array)\n",
    "            feat = model.predict(img_array, verbose=0)\n",
    "            features.append(feat.flatten())\n",
    "            labels.append(label_index)\n",
    "    return np.array(features), np.array(labels)\n",
    "\n",
    "# Extract MobileNetV2 features\n",
    "mobilenet_train, mobilenet_train_labels = extract_deep_features(\"Split_IMG_CLASSES/train\", model, mobilenet_preprocess)\n",
    "mobilenet_test, mobilenet_test_labels = extract_deep_features(\"Split_IMG_CLASSES/test\", model, mobilenet_preprocess)\n",
    "\n",
    "# Save\n",
    "np.save(\"featuresets/train_mobilenet_features.npy\", mobilenet_train)\n",
    "np.save(\"featuresets/test_mobilenet_features.npy\", mobilenet_test)\n",
    "np.save(\"featuresets/train_mobilenet_labels.npy\", mobilenet_train_labels)\n",
    "np.save(\"featuresets/test_mobilenet_labels.npy\", mobilenet_test_labels)\n",
    "\n",
    "print(\"\\n MobileNetV2 features extracted and saved.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34a33509-26c8-4d09-9171-8c7fab45d5e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import cv2\n",
    "from tqdm import tqdm\n",
    "from tensorflow.keras.applications import DenseNet121\n",
    "from tensorflow.keras.applications.densenet import preprocess_input as densenet_preprocess\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.preprocessing import image\n",
    "\n",
    "# Load DenseNet121 model (without top layer, with global average pooling)\n",
    "base_model = DenseNet121(weights='imagenet', include_top=False, pooling='avg')\n",
    "model = Model(inputs=base_model.input, outputs=base_model.output)\n",
    "\n",
    "def extract_deep_features(base_dir, model, preprocess_func):\n",
    "    features = []\n",
    "    labels = []\n",
    "    class_names = sorted(os.listdir(base_dir))\n",
    "    for label_index, class_name in enumerate(class_names):\n",
    "        class_path = os.path.join(base_dir, class_name)\n",
    "        for img_name in tqdm(os.listdir(class_path), desc=f\"{class_name}\"):\n",
    "            img_path = os.path.join(class_path, img_name)\n",
    "            img = cv2.imread(img_path)\n",
    "            if img is None:\n",
    "                continue\n",
    "            img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "            img = cv2.resize(img, (224, 224))\n",
    "            img_array = image.img_to_array(img)\n",
    "            img_array = np.expand_dims(img_array, axis=0)\n",
    "            img_array = preprocess_func(img_array)\n",
    "            feat = model.predict(img_array, verbose=0)\n",
    "            features.append(feat.flatten())\n",
    "            labels.append(label_index)\n",
    "    return np.array(features), np.array(labels)\n",
    "\n",
    "# Extract DenseNet features\n",
    "densenet_train, densenet_train_labels = extract_deep_features(\"Split_IMG_CLASSES/train\", model, densenet_preprocess)\n",
    "densenet_test, densenet_test_labels = extract_deep_features(\"Split_IMG_CLASSES/test\", model, densenet_preprocess)\n",
    "\n",
    "# Save\n",
    "np.save(\"featuresets/train_densenet_features.npy\", densenet_train)\n",
    "np.save(\"featuresets/test_densenet_features.npy\", densenet_test)\n",
    "np.save(\"featuresets/train_densenet_labels.npy\", densenet_train_labels)\n",
    "np.save(\"featuresets/test_densenet_labels.npy\", densenet_test_labels)\n",
    "\n",
    "print(\"\\n DenseNet121 features extracted and saved.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbf81e69-b3b2-4074-941b-9f92693c2079",
   "metadata": {},
   "outputs": [],
   "source": [
    "#upto this point we had all 7 classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c949bf67-abbf-4713-a092-7f01b93744b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "# Load features\n",
    "train_manual = np.load(\"featuresets/train_manual_features.npy\")\n",
    "test_manual = np.load(\"featuresets/test_manual_features.npy\")\n",
    "\n",
    "train_mobilenet = np.load(\"featuresets/train_mobilenet_features.npy\")\n",
    "test_mobilenet = np.load(\"featuresets/test_mobilenet_features.npy\")\n",
    "\n",
    "train_densenet = np.load(\"featuresets/train_densenet_features.npy\")\n",
    "test_densenet = np.load(\"featuresets/test_densenet_features.npy\")\n",
    "\n",
    "train_labels = np.load(\"featuresets/train_manual_labels.npy\")  # All labels are aligned\n",
    "test_labels = np.load(\"featuresets/test_manual_labels.npy\")\n",
    "\n",
    "# Check dimensions\n",
    "print(\"Manual:\", train_manual.shape)\n",
    "print(\"MobileNet:\", train_mobilenet.shape)\n",
    "print(\"DenseNet:\", train_densenet.shape)\n",
    "print(\"Labels:\", train_labels.shape)\n",
    "\n",
    "# Combine features\n",
    "X_train = np.hstack((train_manual, train_mobilenet, train_densenet))\n",
    "X_test = np.hstack((test_manual, test_mobilenet, test_densenet))\n",
    "\n",
    "print(\"Combined train shape:\", X_train.shape)\n",
    "print(\"Combined test shape:\", X_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93b76120-08d5-4f01-977e-b2cf8e58e041",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "# 🔁 Load combined feature arrays and labels (already loaded if you're in Colab)\n",
    "# X_train, X_test, train_labels, test_labels already defined\n",
    "# If not, reload them before this block.\n",
    "\n",
    "# 🎯 Remove class 6 from training and testing sets\n",
    "class_to_remove = 6\n",
    "\n",
    "train_mask = train_labels != class_to_remove\n",
    "test_mask = test_labels != class_to_remove\n",
    "\n",
    "X_train_filtered = X_train[train_mask]\n",
    "X_test_filtered = X_test[test_mask]\n",
    "y_train_filtered = train_labels[train_mask]\n",
    "y_test_filtered = test_labels[test_mask]\n",
    "\n",
    "# 🔄 Train SVM\n",
    "svm = SVC(probability=True, kernel='rbf', C=10, gamma='scale', random_state=42)\n",
    "svm.fit(X_train_filtered, y_train_filtered)\n",
    "y_pred = svm.predict(X_test_filtered)\n",
    "\n",
    "# 📊 Evaluate\n",
    "print(\"\\n🧼 Removed Class 6\")\n",
    "print(classification_report(y_test_filtered, y_pred))\n",
    "print(\"Filtered SVM Accuracy:\", accuracy_score(y_test_filtered, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f4e3eec-92d7-4f8e-9645-6d4f2c72cc38",
   "metadata": {},
   "outputs": [],
   "source": [
    "#due to indexing 0-6 and 1-7 in original dataset i am \n",
    "#sometimes confused if we eliminated last or the last but one class, i beilve we eliminated the last class but you please cross check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4efa99c4-7901-4559-aa06-7c36bb69a49d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Load features and labels\n",
    "train_manual    = np.load(\"featuresets/train_manual_features.npy\")\n",
    "test_manual     = np.load(\"featuresets/test_manual_features.npy\")\n",
    "train_mobilenet = np.load(\"featuresets/train_mobilenet_features.npy\")\n",
    "test_mobilenet  = np.load(\"featuresets/test_mobilenet_features.npy\")\n",
    "train_densenet  = np.load(\"featuresets/train_densenet_features.npy\")\n",
    "test_densenet   = np.load(\"featuresets/test_densenet_features.npy\")\n",
    "train_labels    = np.load(\"featuresets/train_manual_labels.npy\")\n",
    "test_labels     = np.load(\"featuresets/test_manual_labels.npy\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfcafc63-6cdb-4b41-a705-1575f3516f0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ✅ Combine features\n",
    "X_train = np.hstack((train_manual, train_mobilenet, train_densenet))\n",
    "X_test  = np.hstack((test_manual, test_mobilenet, test_densenet))\n",
    "\n",
    "print(\"Train shape:\", X_train.shape)\n",
    "print(\"Test shape:\", X_test.shape)\n",
    "print(\"Labels:\", train_labels.shape)\n",
    "\n",
    "# 🔍 Remove Class 6\n",
    "class_to_remove = 6\n",
    "train_mask = train_labels != class_to_remove\n",
    "test_mask  = test_labels != class_to_remove\n",
    "\n",
    "X_train_filtered = X_train[train_mask]\n",
    "X_test_filtered  = X_test[test_mask]\n",
    "y_train_filtered = train_labels[train_mask]\n",
    "y_test_filtered  = test_labels[test_mask]\n",
    "\n",
    "print(\"Filtered train shape:\", X_train_filtered.shape)\n",
    "print(\"Filtered test shape:\", X_test_filtered.shape)\n",
    "\n",
    "# 🤖 Import models\n",
    "from sklearn.ensemble import VotingClassifier, RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "# 🧠 3-Model Ensemble (SVM + XGB + RF)\n",
    "ensemble = VotingClassifier(\n",
    "    estimators=[\n",
    "        ('svm', SVC(probability=True, C=10, gamma='scale', random_state=42)),\n",
    "        ('xgb', XGBClassifier(use_label_encoder=False, eval_metric='mlogloss', random_state=42)),\n",
    "        ('rf', RandomForestClassifier(n_estimators=150, random_state=42))\n",
    "    ],\n",
    "    voting='soft',\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "# 🏋️ Train and Predict\n",
    "ensemble.fit(X_train_filtered, y_train_filtered)\n",
    "y_pred = ensemble.predict(X_test_filtered)\n",
    "\n",
    "# 📊 Evaluate\n",
    "print(\"\\n🤝 Ensemble Voting Results (Top 3 Models)\")\n",
    "print(classification_report(y_test_filtered, y_pred))\n",
    "print(\"Voting Ensemble Accuracy:\", accuracy_score(y_test_filtered, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03c7b03e-b438-478f-8ff4-3f170294964a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "",
   "name": ""
  },
  "language_info": {
   "name": ""
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
